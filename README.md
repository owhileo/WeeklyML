# 基础提升计划



## 简介

#### 时间

 3月~6月20日(16周)[~9月(26周)]

初定2周一次讨论会，只用下学期一学期有7~8次讨论会；到研究生开学为止的话有10~13次讨论会

视每周任务难度酌情可调整3周一次

#### 任务

基础知识/原理学习 + 现有方法/代码实现 + 至少一种手动实现方法 + 1-2个数据集运行

#### 目标

提升机器学习编程能力，顺便学习、熟练机器学习算法原理



## 整体计划

- 每个人每次选一个模型，完成理论研究、调用现有算法包实现+自己代码实现，并在一个数据集上运行
- 写一个文档，包括理论介绍、代码使用教程、遇到的困难问题、参考文档链接等

- 每次开会(腾讯会议)时大家互相分享，简要讲一下理论，再演示一下代码，分享一下遇到的困难等

- 使用GitHub统一管理代码、文档等内容

- 用latex写文档，顺便熟悉一下latex

- 模型跑不动时可以找老师、师兄开服务器(熟悉linux命令行环境)

  

## 内容安排

### 经典方法（3个月，UCI数据集）

#### 第一回

内容：

- logistic regression
- 决策树
- 朴素贝叶斯
- 最近邻方法

安排：

- 第1～2周：学习理论并实践；
- 第3周：对理论做进一步拓展与探究，并代码实现；
- 第4周：互相学习巩固

#### 第二回

内容：

- libsvm论文及开源代码阅读、使用 

安排：

- 第5周：SVM原理讲解
- 第6周：libsvm论文梳理，与原理讲解
- 第7周：libsvm代码讲解

#### 第三回

- liblinear论文及开源代码阅读、使用
- 第8周 liblinear讲解、与libsvm对比
- 第9周 liblinear代码阅读

#### 第四回 

内容：

- XGboost、Lightgbm (论文及开源代码阅读、使用)

安排：

- 第10周 XGboost论文讲解
- 第11周 XGboost代码及使用讲解
- 第12周 实践&调参

#### 第五回

- 聚类(K-means, DBSCAN, GMM，t-sne)
- 降维(PCA,LDA)
- 概率图模型 (LDA主题模型, HMM)

安排：

- 第13周 算法理论讲解及实现
- 第14周 对理论做进一步拓展与探究
- 第15周 读书，学习聚类部分内容



### 深度学习方法（2个月，数据集：图像、视频、声音、(文本))

#### 第六回

从以下模型中选取，用pytorch实现：

- 不熟悉DNN的话：多层感知机MLP的原理，以及BP的原理
- 卷积网络：LeNet-5、AlexNet、VGG、ResNet、DenseNet、MobileNet
- 序列网络：RNN、LSTM、GRU、transformer及其组成深度模型(如Bert)
- 生成式模型：GAN、VAE

安排：

- 第16周 算法理论讲解及实现

改变计划，完成从基础知识开始的深度学习课程学习与编程练习

- 第17周
  - 基础概念，网络结构等：M-P模型，感知机模型，多层感知机模型,常见激活函数
  - 基本优化方法：梯度下降，前向传播，反向传播，学习率，可以的话列举一下常见损失函数
  - 实际训练中的其它问题：随机梯度下降，Minibatch,batch normalization、网络权重初始化等
  - 进阶优化方法：除随机梯度下降以外的，各种梯度下降方法的改进版本、加速等；概述比较一下不同optimizer(除SGD外)，如MIT课件里提到了4种
  - 正则化：过拟合，正则化方法，Dropout机制等，可以参考“07_regularization.pdf”和书第7章中提到的多种方法，主要关注于Dropout和早停

